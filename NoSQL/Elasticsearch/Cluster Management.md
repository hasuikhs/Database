# 6. Cluster Management

## 6.1 클러스터 설정 API
- ES 서비스 **운영 중 여러 설정을 동적으로 변경**해야할 경우 존재
- 클러스터 설정 API는 해당 상황에서 관련 설정을 확인 및 변경 가능한 API

```bash
# 클러스터 설정 확인 방법
GET _cluster/settings
```
```bash
PUT /_cluster/settings
{
  "persistent": { },  # 클러스터 풀 리스타트로 전체 재시작해도 유지
  "transient": { }    # 클러스터 전체 재시작 시 내용 삭제 (임시)
}
```
- `persistent`, `transient`를 꼭 동시에 설정할 필요는 없음
  - 단, 두 개에 동일한 설정 지정되면 **`transient`의 설정이 우선 순위**
  - 우선순위는 `transient` > `persistent` > `config/elasticsearch.yml` 순서
- 이전의 설정을 본문에 다시 넣을 필요없이 새롭게 추가하거나 변경하고 싶은 서정만 원하는 만큼 지정
- 클러스터 설정 API를 통해 지정한 설정을 제거하려면 값을 `null`로 지정

## 6.2 cat API를 통한 클러스터 관리와 모니터링
- cat API는 ES의 여러 현재 상태 조회 가능한 API

- `GET _cat/health`
  - 클러스터의 전반적인 상태를 빠르게 조회
- `GET _cat/indices`
  - 인덱스의 종류와 상태 조회
- `GET _cat/nodes`
  - 각 노드의 상태 조회
- `GET _cat/shards`
  - 샤드의 상태 조회
- `GET _cat/segments`
  - 루씬 세그먼터의 상태 조회
- `GET _cat/recovery`
  - 진행 중이거나 완료된 샤드 복구 작업에 대한 정보 조회
- `GET _cat/allocation`
  - 샤드 할당과 관련된 정보 조회
- `GET _cat/thread_pool`
  - 각 노드의 스레드 풀 상태 조회
- `GET _cat/master`
  - 현재 마스터로 선출된 노드 확인

## 6.3 인덱스 운영 전략
- 인덱스를 운영할 대 고려해야할 중요한 요소와 운영 이슈에 대응하기 위한 기능

##### 템플릿과 명시적 매핑 활용
  - 실제 서비스 운영에서는 매핑이 **동적으로 생성되도록 하기보다는 최대한 명시적**으로 매핑을 지정
  - 하지만, 서비스에 따라서 데이터를 컨트롤할 수 없다면 신규 필드가 추가될 수 있는데, 이 때는 **인덱스 템플릿과 동적 템플릿을 최대한 활용**

##### 라우팅 활용
  - 라우팅 지정은 성능을 유의미하게 상승
  - 사전에 서비스 요건과 데이터 특성 등을 면밀히 파악하고 어떤 값을 라우팅으로 지정해야 가장 효율적일지를 설계
  - 라우팅을 결정했다면 해당 인덱스에 접근하는 모든 클라이언트도 라우팅 정책 내용을 숙지해야 함

##### 시계열 인덱스 이름
  - 시계열 데이터를 색인한다면 **인덱스 이름에도 시간값을 넣는 방법** 고려
  - **오래된 데이터를 백업하고 삭제하는 것이 편해짐**
  - 데이터 노드를 hot-warm-cold-frozen 티어로 구분해 클러스터를 구성하는 데이터 티어 구조에도 좋음
  - 템플릿과의 궁합도 좋음
    - 인덱스가 주기적으로 여러 번 생성되기 때문
    - 인덱스의 매핑이나 설정을 변경할 때 템플릿만 변경하면 이후 생성되는 인덱스는 새 매핑과 설정으로 생성
    - 샤드의 크기와 개수를 조정에도 효과적
  - 성능에서도 이익을 볼 수 있음
    - 시간이 어느 정도 지난 인덱스에는 더 이상 새 데이터가 색인되지 않아 내용이 고정된 상태가 됨
    - 즉, 새로운 세그먼트 병합을 지속적으로 수행할 필요 없음
  - 하지만 **모든 상황에서 시계열 이름을 쓸 수 없음**

##### alias
  - 이미 존재하는 인덱스를 다른 이름으로도 가리키도록하는 기능
    - **서비스에 직접 활용되는 데이터를 들고 있는 인덱스, 요건 등이 변할 것이 예상되는 인덱스라면 고려**
    - 실제 인덱스 이름이 아닌 이 alias를 가리키도록 설계
      - 매핑이나 설정 등에 큰 변화가 필요할 때 **새 인덱스를 미리 만들고 alias가 가리키는 인덱스만 변경하면 운영 중에 새 인덱스로 이동 가능**
  - 한 alias가 하나 이상의 인덱스를 가리키도록 지정 가능
  ```bash
  POST _aliases
  {
    "actions": [
      {
        "add": {
          "index": "my_index",
          "alias": "my_alias_name"
        }
      },
      {
        "add": {
          "index": "my_index2",
          "alias": "my_alias_name",
          "is_write_index": true # 수정, 삭제 등 쓰끼 작업의 경우 해당 인덱스를 대상으로 작업, 해당 필드가 없으면 쓰기 작업 불가능
        }
      }
    ]
  }
  ```
    - `my_alias_name`을 대상으로 검색하면 위 두 인덱스를 모두 대상으로 검색
    - 다만, 여러 인덱스를 가리키는 alias는 단건 문서 조회 작업의 대상이 될 수 없음

##### 롤오버
  - 하나의 alias에 여러 인덱스를 묶고 한 인덱스에만 `is_write_index`를 `true`로 지정하는 구성은 쓰기 담당 인덱스 내 크기가 너무 커지면 새로운 인덱스를 생성해서 같은 alias로 묶은 뒤 `is_write_index`를 새 인덱스로 옮기는 방식으로 운영됨
  - 롤오버는 이 작업을 한 번에 묶어서 수행하는 기능

  ```bash
  POST [롤오버 대상]/_rollover # 롤오버 대상은 alias의 이름 또는 데이터 스트림 이름
  ```

  - 롤오버 수행할 alias 내 is_write_index 인덱스 이름은 반드시 `/^.*-\d+$/` 패턴을 따라야 함
    - 인덱스 이름의 숫자 부분은 반드시 여섯 자리일 필요는 없지만, 롤오버가 자동으로 생성해줄 때는 여섯 자리를 맞춰줌

  ```bash
  POST [롤오버 대상]/_rollover/[생성할 새 인덱스 이름] # 롤오버로 생성될 인덱스 이름을 직접 명시도 가능, 형식 X
  ```

##### 데이터 스트림
  - 데이터 스트림은 내부적으로 여러 개의 인덱스로 구성
    - 데이터 스트림에 포함된 모든 인덱스를 대상으로 검색 수행
    - 문서 추가 색인할 떄는 가장 최근에 생성된 단일 인덱스에 새 문서가 들어감
  - 데이터 스트림은 마치 여러 인덱스를 묶고 `is_write_index` 인덱스를 하나 둔 alias와 유사하게 동작
    - 데이터 스트림은 이런 구조의 **alias를 인덱스 템플릿과 연계해서 조금 더 시계열 데이터 사용 패턴에 맞게 정형화**
    - 차이점
      - 데이터 스트림을 구성하는 인덱스는 뒷받침 인덱스(backing index)라 불리며 모두 hidden 속성
        - 뒷받침 인덱스: 이름 패턴 고정, 롤오버 시 명시적 새 인덱스 이름 지정 불가
      - 반드시 인덱스 템플릿과 연계해서 생성
      - 문서 추가는 가능하지만 업데이트 작업은 불가능
      - 반드시 @timestamp 필드가 포함된 문서만을 취급
  - 데이터 스트림은 편리하게 자동으로 많은 것을 관리 가능케해주는 대신 제약도 크기에 적절한 용도에 맞게 사용해야 함
    - 특정 시스템의 모니터링용 지표 데이터를 수집하기 위한 용도 등 그냥 문제 시간대의 데이터를 버려도 큰 문제가 없는 경우에 사용하기 좋음

##### reindex
  - 원본 인덱스 내 문서의 _source를 읽어 대상 인덱스에 새로 색인하는 작업
  ```bash
  POST _reindex
  {
    "source": {
      "index": "source_index"
    },
    "dest": {
      "index": "target_index"
    },
    "conflicts": "abort"  # proceed로 지정하면 충돌이 발생한 문서는 건너뜀, abort는 해당 부분까지만 진행되고 취소
  }
  ```
  - reindex는 작업 특성상 매핑에서 _source가 활성화되어 있어야 함
    - 일반적으로 _source는 비활성화하는 일은 없어야 함
    - 운영 이슈에 대처할 수 잇는 여러 수단 중 가장 마지막 수단이 reindex이기 때문
      - reindex는 주로 관리적인 목적으로 호출하기 때문에 작업의 크기가 큰 경우가 많음
        - 많은 양의 데이터를 읽고, 새 인덱스에 쓰는 과정을 포함하여 리소스를 많이 사용
      - reindex 요청을 부낸 후 작업이 끝날 때까지 대기하는 것은 비효율적

##### shrink로 샤드 개수 줄이기
  - shrink는 샤드의 개수를 줄이면서 인덱스를 새로 생성하는 작업
  - 인덱스를 새로 만드는 것이니 reindex와 차이가 없는 기능처럼 보임
    - reindex는 기본적으로 새 인덱스에 문서를 다시 새로 색인하는 과정
    - shrink는 기존 인덱스의 세그먼트를 새 인덱스로 하드 링크, 샤드 개수를 제외한 인덱스 설정과 매핑 유지
  - 하드 링크를 해야 하기 때문에 reindex에 비해 제약이 많음
    - `index.blocks.write` 설정을 `true`로 지정해 읽기 전용 상태여야 함
    - 한 노드가 로컬에 모든 샤드를 보유하고 있어야 함
    - 인덱스 상태가 green이어야 함
    - 새로 생성할 인덱스 샤드 개수는 원본 인덱스 샤드 개수의 약수여야 가능
      - shink 과정에서 원본 인덱스의 각 샤드에서 데이터를 새 인덱스의 적은 수의 샤드로 옮겨야 함
      - **데이터의 균일한 분포와 효율적인 할당을 보장하기 위해 약수**여야 함
  - 실무에서 관리적인 목적으로 shrink를 직접 사용할 일은 많지 않음
    - 운영 중인 인덱스의 샤드 개수를 줄여야만 한다면 reindex를 진행 수행하는 것이 제약사항을 감수할 필요 없음
    - 다만, 인덱스 생명 주기 관리 기능을 활용하고 있다면, 운영 상황에 따라 인덱스 생명 주기 정책 내에서 이용해 볼만 함

##### split으로 샤드 개수 늘이기
  - split은 샤드의 개수를 늘리면서 인덱스를 새로 생성하는 작업
  - split 역시 shrink와 마찬가지로 새 인덱스 생성 후에 원본 인덱스의 세그먼트를 하드 링크하는 방식으로 진행
  - 제약사항
    - 인덱스 생성 당시 `index.number_of_routing_shards` 설정을 넉넉히 지정해 생성
      - `index.number_of_routing_shards` 설정은 라우팅 과정에서 라우팅 값을 몇 덩어리로 쪼갤지 지정
      - 이 값의 기본값은 `index.number_of_shards`와 같음
      - `index.number_of_shards` 값의 배수로 지정해야 함
    - split 작업 시 새 인덱스의 샤드 개수는 `index.number_of_shards`의 배수이자 `index.number_of_routing_shards`의 약수로 지정
    - 샤드의 개수를 늘리는 작업이므로 `index.number_of_shards`의 값보다는 커야 함
  - 읽기 전용 인덱스에만 작업 가능한 제약 때문에 운영 도중 사용할 일이 많지 않고, alias와 reindex를 조합해 사용하는 경우가 많음

##### 다중 필드
  - 필드 하나에 여러 이름을 붙인 뒤 각각 다른 매핑을 적용해서 사용 가능케 해줌
  ```bash
  PUT [index]/_mapping
  {
    "properties": {
      "my_string_field": {
        "type": "keyword", # 여기까지가 기존의 매핑
        "fields": {
          "text_standard": {
            "type": "text",
            "analyzer": "standard"
          },
          "text_whitespace": {
            "type": "text",
            "analyzer": "whitespace"
          }
        }
      }
    }
  }
  ```
  - 위처럼 `text_standard`, `text_whitespace`를 추가로 지정하면, `my_string_field`로 접근할 때는 `keyword` 타입으로, `my_string_field.text_standard`로 접근하면 standard 애널라이저를 적용한 `text` 타입으로 동작
  - **인덱스에 한 번 지정된 매핑은 변경될 수 없지만, 새 매핑을 추가하는 것은 가능하기에 운영 도중 다중 필드 추가 가능**
    - 단, 다중 필드 매핑이 추가된 이후 들어오는 데이터부터 적용되며, 기존 데이터는 다시 색인을 해야 적용
    - 색인이 추가되는 만큼 색인 성능이 감소하고, 디스크와 메모리를 조금 더 사용하게 됨
    - 이 부분에서 문제가 된다면 결국 reindex를 고려해야 함

##### 타입이 계속 변경되는 데이터
  - 같은 필드 이름으로 여러 타입의 값이 들어올 수도 있음
  - ES는 특성상 그런 형태의 사용에 적합하지 않으며, 이런 데이터는 색인되지 않는다는 사실을 클라이언트에게 주지시켜야 함
  - 다만, 필요하다면 타입을 `object`로 지정한 뒤 `enabled: false`를 지정하는 방법 사용 가능
    - 타입 충돌로 인한 문서 색인 거부는 발생하지 않겠지만 해당 필드에 대한 검색은 포기해야 함